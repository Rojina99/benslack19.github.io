Over the holiday break, I set out to create a customized Python scatter plot function. (Yes, I know that's a weird thing to do over the holidays. I hid the nerd-ness from my family.) While creating this function, I realized that there were cases where the plot and/or legend rendering could go out of whack. This could happen if the feature where I wanted marker size to be represented has a skewed distributions, contain 0, or contain negative values. Therefore, creating a data frame that has features that range in complexity was important for evaluating my custom scatterplot function.

I created a data frame with 1000 samples (AKA as m or training examples). To evaluate the robustness of my scatter plot visualization, I made up features that have regression variables representing nine distributions: uniform, Gaussian, bimodal, lognormal, Poisson, negative binomial, chi-square, a distribution containing a 6 log-order range of numbers, and a left-skewed distribution. There are tons more probability distributions than I ever thought, but I settled on using some distributions that were common for data science. (That last link also does a nice job explaining the various distributions.) Some of the features will contain values that are positive, negative, fractions, or zero.
